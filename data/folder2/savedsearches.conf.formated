
[my search #1]
alert.digest_mode = True
alert.suppress = 0
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -3mon@d
cron_schedule = 0 0 * * *
search = index=_internal sourcetype=s*
      | stats latest(source) as source latest(sourcetype) as sourcetype by message
      | table source message sourcetype

[my search #2]
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
search = index=_internal
         | head 4
         | eval numberString = tostring(123456.78, "commas") 
         | table numberString

[my search #3]
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
enableSched = 1
search = index=_internal
      | head 1
      | eval first1 = "123 | search | 456"
      | eval second2= "123 | 'search | 456'"
      | eval third3= "123       | \"search | 456\""
      | table first1 second2 third3

[my search #4 EO_CT_XPE_TOO_LONG_BASE_DATA]
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
search = * sourcetype="BASE_DATA"

[my search #5 append]
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
search =
            | savedsearch EO_CT_XPE_TOO_LONG_BASE_DATA
            | append
            [ `eo_xx_parser_too_long_threshold(too_long_xe_sepa)` ]
            | search MONITORINGPOINT=EO_CT_XP_AUS
            | stats
            , max(active) as active
            , count as value
            | eval value=if(active=0,"-",value-1)
            | eval range=case(active=0,"none", value=0, "green", value!=0, "red")
            | eval _time=now()
            | tablevaluerange_time

[my search #6 brackets]
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
search =
         | metadata type=hosts index=_internal
         | search NOT(host="YourSplunkServers") 
         | tablehostrecentTime
         | eval age=(now()-recentTime)
         | eval status=if(age < 300, "UP", "DOWN")
         | table host status


[my search #7 eval-if]
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
search =
         | metadata type=hosts index=_internal
         | search NOT(host="YourSplunkServers") 
         | table host recentTime
         | eval age=now()-recentTime
         | eval status=if(age < 300, "UP", "DOWN")
         | table host status


[my search #8 join]
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
search = index="_internal"
         | stats sum(kb) as kb by splunk_server
         | join type="outer" splunk_server
         [ search index="_internal" source="*metrics.log" group=queue name=parsingqueue
         | chart perc95(current_size_kb) as p95sz by splunk_server ]

[my search #9 long]
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
search = sourcetype = CI_* BULK_KEY=$args.BULK_KEY$ ABC <= 5
         | eval BULK_TRX_NUMBER = coalesce(BULK_TRX_NUMBER, "12,3'4|5") 
         | eval BULK_CONTROL_SUM=coalesce(BULK_CONTROL_SUM, "678 eval 901")
         | eval BULK_NAME=coalesce(BULK_NAME, "n.a.")
         | eval BULK_NAME_ORIGINAL=coalesce(BULK_NAME_ORIGINAL, "n.a. search ")
         | eval SEPA_MESSAGE_TYPE=coalesce(SEPA_MESSAGE_TYPE, "n.a.")
         | eval FILE_TRX_NUMBER=coalesce(FILE_TRX_NUMBER, "n.a.")
         | eval FILE_NUMBER=coalesce(FILE_NUMBER, "n.a.")
         | eval BULK_CONTROL_SUM_XPE=coalesce(BULK_CONTROL_SUM_XPE, "0")
         | eval BULK_TRX_NUMBER_XPE=coalesce(BULK_TRX_NUMBER_XPE, "0")
         | eval CUSTOMER_IBAN=coalesce(DEBTOR_IBAN, CREDITOR_IBAN, "diverse")
         | `to_string_commas_locale($args.ACTIVE_LOCALE$, BULK_CONTROL_SUM)`
         | eval BULK_CONTROL_SUM=thousanders_BULK_CONTROL_SUM
         | `to_string_commas_locale($args.ACTIVE_LOCALE$, BULK_CONTROL_SUM_XPE)`
         | eval BULK_CONTROL_SUM_XPE=thousanders_BULK_CONTROL_SUM_XPE
         | `to_string_commas_locale($args.ACTIVE_LOCALE$, BULK_TRX_NUMBER)`
         | eval BULK_TRX_NUMBER=thousanders_BULK_TRX_NUMBER
         | `to_string_commas_locale($args.ACTIVE_LOCALE$, BULK_TRX_NUMBER_XPE)`
         | eval BULK_TRX_NUMBER_XPE=thousanders_BULK_TRX_NUMBER_XPE
         | `to_string_commas_locale($args.ACTIVE_LOCALE$, FILE_TRX_NUMBER)`
         | eval FILE_TRX_NUMBER=thousanders_FILE_TRX_NUMBER
         | eval XPE_ORIGIN=coalesce(XPE_ORIGIN, "n.a.")
         | stats latest(CUSTOMER_IBAN) as "01. Customer IBAN"
         , latest(BULK_EXECUTION_DATE) as "02. Requested Date"
         , latest(BULK_NAME_ORIGINAL) as "03. Bulk Id"
         , latest(BULK_CONTROL_SUM) as "04. Customer Bulk Amount"
         , latest(BULK_CONTROL_SUM_XPE) as "05. Calculated Bulk Amount"
         , latest(BULK_TRX_NUMBER) as "06. Customer Bulk Trx"
         , latest(BULK_TRX_NUMBER_XPE) as "07. Calculated Bulk Trx"
         , latest(MONITORINGPOINT) as "08. Last Status"
         , latest(TIMESTAMP) as "09. Status Time"
         , latest(SERVICE_TYPE) as "10. Service"
         , latest(SEPA_MESSAGE_TYPE) as "11. SEPA Message Type"
         , latest(FILE_NAME_ORIGINAL) as "12. File Id"
         , latest(FILE_TRX_NUMBER) as "13. File Trx"
         , latest(FILE_CREATION_DATE) as "14. File Creation Date"
         , latest(XPE_ORIGIN) as "15. Origin"
         , latest(FILE_NUMBER) as "16. XPE File Number" by BULK_KEY
         | fields - BULK_KEY
         | untable _time "Field name"
         | table "Field table name"Content


[my search #10 simple]
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
search = search source = mytable mycolumn = value
      | stats avg(mycolumn) by mycolumn
      | search TST123 = value
      | fieldsmycolumnavg(mycolumn)
      | eval test = "abc"."xyz".'ghf'."'hij'".'hhh'
      | search source = mytabl1 mycolumn = value
      | table ABC


[my search #11 strings]
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
search = index=_internal
      | head 2
      | eval first1 = "123 | search | 456"
      | eval second2= "123 | 'search | 456'"
      | eval third3= "123 | \"search | 456\""
      | table first1 second2 third3

[my search #12 subsearch]
auto_summarize.dispatch.earliest_time = -1d@h
cron_schedule = 0 0 * * *
search = index=foo sourcetype=bar field=quux
         [
         | search *
         | stats count by dimension ]
         [ search some really really long sub_searc
         | eval subsearch=fields
         | rex field=subsearch "(?<extract>\d+)"
         | eval omg=how_much_more ]
         | stats count by something
         | eval field1=stuff
         | eval field2=more_stuff
         | timechart sum(something) by something_else

